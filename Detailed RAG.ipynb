{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e973dd-c46f-4629-a16d-c269bef16429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-3.2.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting google-cloud-documentai\n",
      "  Using cached google_cloud_documentai-3.5.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.105.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "Collecting vertexai\n",
      "  Downloading vertexai-1.71.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.26.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-storage) (2.40.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.15.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-storage) (2.25.1)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.2 (from google-cloud-storage)\n",
      "  Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.7.2 (from google-cloud-storage)\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.22.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-storage) (2.32.3)\n",
      "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage)\n",
      "  Downloading google_crc32c-1.7.1-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-documentai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-documentai) (5.29.5)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Collecting google-cloud-storage\n",
      "  Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Using cached google_cloud_bigquery-3.35.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Using cached google_cloud_resource_manager-1.14.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting shapely<3.0.0 (from google-cloud-aiplatform)\n",
      "  Downloading shapely-2.1.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting google-genai<2.0.0,>=1.0.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_genai-1.27.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform) (4.12.2)\n",
      "Collecting docstring_parser<1 (from google-cloud-aiplatform)\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (4.9.1)\n",
      "Collecting packaging>=14.3 (from google-cloud-aiplatform)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform)\n",
      "  Using cached grpc_google_iam_v1-0.14.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from shapely<3.0.0->google-cloud-aiplatform) (1.26.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (8.5.0)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.14.0)\n",
      "Using cached google_cloud_documentai-3.5.0-py3-none-any.whl (299 kB)\n",
      "Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Downloading vertexai-1.71.1-py3-none-any.whl (7.3 kB)\n",
      "Downloading google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 7.7 MB/s eta 0:00:00\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Using cached google_cloud_bigquery-3.35.0-py3-none-any.whl (256 kB)\n",
      "Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Using cached google_cloud_resource_manager-1.14.2-py3-none-any.whl (394 kB)\n",
      "Downloading google_crc32c-1.7.1-cp311-cp311-win_amd64.whl (33 kB)\n",
      "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading shapely-2.1.1-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 10.3 MB/s eta 0:00:00\n",
      "Using cached grpc_google_iam_v1-0.14.2-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: shapely, packaging, google-crc32c, docstring_parser, google-resumable-media, grpc-google-iam-v1, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-documentai, google-cloud-bigquery, google-cloud-aiplatform, vertexai\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "Successfully installed docstring_parser-0.17.0 google-cloud-aiplatform-1.71.1 google-cloud-bigquery-3.35.0 google-cloud-core-2.4.3 google-cloud-documentai-3.5.0 google-cloud-resource-manager-1.14.2 google-cloud-storage-2.19.0 google-crc32c-1.7.1 google-resumable-media-2.7.2 grpc-google-iam-v1-0.14.2 packaging-25.0 shapely-2.1.1 vertexai-1.71.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-core 0.3.68 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "langchain-google-genai 2.1.6 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries (run only if not already installed)\n",
    "!pip install google-cloud-storage google-cloud-documentai google-cloud-aiplatform vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1dc08a-5920-4847-8948-e9ed9b9f73c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from google.cloud import storage, documentai_v1 as documentai\n",
    "from vertexai.preview import rag\n",
    "from vertexai.generative_models import GenerativeModel, Tool\n",
    "import vertexai\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Path to your service account key JSON file\n",
    "key_path = r\"C:\\Users\\jagad\\Agentic AI-planner and content generator\\agentic-ai-project-466814-869df6973c65.json\"\n",
    "\n",
    "# Create credentials object\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "from google.cloud import storage\n",
    "PROJECT_ID = \"agentic-ai-project-466814\"\n",
    "client = storage.Client(project=PROJECT_ID, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841a1b94-ec7a-40ee-a89e-c7e29955f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your project and location\n",
    "PROJECT_ID = \"agentic-ai-project-466814\"\n",
    "LOCATION = \"us-central1\"  # Use supported Vertex AI RAG Engine region\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f2c7b-e793-4e33-9342-18333a731023",
   "metadata": {},
   "source": [
    "\n",
    "try:\n",
    "    client = storage.Client(credentials=credentials, project=PROJECT_ID)\n",
    "    bucket_name = \"studyplanandcontent\"\n",
    "    bucket = client.bucket(bucket_name)\n",
    "except Exception as e:\n",
    "    print(f\"[GCS ERROR] Client or bucket initialization failed: {e}\")\n",
    "    raise\n",
    "\n",
    "local_folder = \"C:/Users/jagad/Downloads/iesc1dd\"\n",
    "file_path = \"C:/Users/jagad/Downloads/iesc1dd/iesc103.pdf\"\n",
    "file_name = os.path.basename(file_path)\n",
    "try:\n",
    "    for file_name in os.listdir(local_folder):\n",
    "        blob = bucket.blob(file_name)\n",
    "        blob.upload_from_filename(os.path.join(local_folder, file_name))\n",
    "        print(f\"[UPLOAD SUCCESS] Uploaded {file_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"[GCS UPLOAD ERROR] Uploading {file_name} failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d81afca-0669-41c5-9b21-576221d538ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n",
      "[DOCUMENT AI SUCCESS] Batch processing complete. Check your GCS output folder.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.cloud.documentai_v1 import types\n",
    "processor_id = \"6969be315242bcf5\"\n",
    "region = \"US\"\n",
    "\n",
    "gcs_input_uri = \"gs://studyplanandcontent/iesc106.pdf\"\n",
    "gcs_output_uri = \"gs://studyplanandcontent/output/\"  # Output prefix folder\n",
    "\n",
    "# The full resource name of the processor\n",
    "name = f\"projects/agentic-ai-project-466814/locations/us/processors/6969be315242bcf5\"\n",
    "\n",
    "client = documentai.DocumentProcessorServiceClient(credentials=credentials)\n",
    "# Configure input documents (GCS)\n",
    "gcs_documents = types.GcsDocuments(\n",
    "    documents=[\n",
    "        types.GcsDocument(\n",
    "            gcs_uri=gcs_input_uri, mime_type=\"application/pdf\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_config = types.BatchDocumentsInputConfig(gcs_documents=gcs_documents)\n",
    "\n",
    "# Configure output bucket\n",
    "output_config = types.DocumentOutputConfig(\n",
    "    gcs_output_config=types.DocumentOutputConfig.GcsOutputConfig(\n",
    "        gcs_uri=gcs_output_uri\n",
    "    )\n",
    ")\n",
    "\n",
    "# Construct request\n",
    "request = types.BatchProcessRequest(\n",
    "    name=name,\n",
    "    input_documents=input_config,\n",
    "    document_output_config=output_config\n",
    ")\n",
    "\n",
    "# Process document asynchronously\n",
    "operation = client.batch_process_documents(request=request)\n",
    "print(\"Waiting for operation to complete...\")\n",
    "operation.result(timeout=300)\n",
    "\n",
    "print(\"[DOCUMENT AI SUCCESS] Batch processing complete. Check your GCS output folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "703ee51b-7b86-49c9-8d4c-8752b2d6dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vertexai in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (1.71.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform==1.71.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform[all]==1.71.1->vertexai) (1.71.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (5.29.5)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (25.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.35.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.1.1)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.8.2)\n",
      "Requirement already satisfied: docstring-parser<1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.26.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jagad\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\n"
     ]
    }
   ],
   "source": [
    "!pip install vertexai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf8c9023-33dd-4772-a147-5422e6364662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet google-cloud-storage vertexai numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9afb6cdb-756a-4745-bec1-90cd0bb7b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Initializing Vertex AI...\n",
      "✅ Vertex AI Initialized\n",
      "⏳ Fetching Document AI output JSON...\n",
      "✅ JSON Loaded\n",
      "📄 Text Extracted: 24018 characters\n",
      "⏳ Generating embedding using Vertex AI model...\n",
      "✅ Embedding generated\n",
      "⏳ Uploading embedding to GCS...\n",
      "✅ Embedding uploaded to: gs://studyplanandcontent/embeddingsoutput/iesc106_vector.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "from vertexai import init\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "from vertexai.preview import rag\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = \"agentic-ai-project-466814\"\n",
    "LOCATION = \"us-central1\" \n",
    "BUCKET_NAME = \"studyplanandcontent\"\n",
    "DOC_JSON_PATH = \"output/17996961397770261561/0/iesc106-0.json\"\n",
    "GCS_SAVE_PATH = \"embeddingsoutput/iesc106_vector.npy\"\n",
    "\n",
    "# 🟢 Step 1: Init Vertex AI\n",
    "print(\"⏳ Initializing Vertex AI...\")\n",
    "init(project=PROJECT_ID, location=LOCATION)\n",
    "print(\"✅ Vertex AI Initialized\")\n",
    "\n",
    "# 📥 Step 2: Read Document AI Output JSON from GCS\n",
    "print(\"⏳ Fetching Document AI output JSON...\")\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(DOC_JSON_PATH)\n",
    "docai_json = json.loads(blob.download_as_text())\n",
    "print(\"✅ JSON Loaded\")\n",
    "\n",
    "# 📝 Step 3: Extract Text\n",
    "document_text = docai_json.get(\"text\", \"\")\n",
    "print(f\"📄 Text Extracted: {len(document_text)} characters\")\n",
    "\n",
    "# 🤖 Step 4: Generate Embedding\n",
    "print(\"⏳ Generating embedding using Vertex AI model...\")\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "embedding_response = embedding_model.get_embeddings([document_text])\n",
    "embedding_vector = embedding_response[0].values\n",
    "print(\"✅ Embedding generated\")\n",
    "\n",
    "# ☁️ Step 5: Upload Embedding Directly to GCS (No local file)\n",
    "print(\"⏳ Uploading embedding to GCS...\")\n",
    "buffer = BytesIO()\n",
    "np.save(buffer, np.array(embedding_vector))\n",
    "buffer.seek(0)\n",
    "\n",
    "embedding_blob = bucket.blob(GCS_SAVE_PATH)\n",
    "embedding_blob.upload_from_file(buffer, content_type=\"application/octet-stream\")\n",
    "print(f\"✅ Embedding uploaded to: gs://{BUCKET_NAME}/{GCS_SAVE_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97558fac-f643-48d4-b860-2785ccdd2136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded document embedding: (768,)\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "blob = bucket.blob(GCS_SAVE_PATH)\n",
    "buffer = BytesIO()\n",
    "blob.download_to_file(buffer)\n",
    "buffer.seek(0)\n",
    "doc_embedding_vector = np.load(buffer)\n",
    "print(f\"✅ Loaded document embedding: {doc_embedding_vector.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2fc6750-2bb6-44ae-8a35-f46a3ac0e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"What is a nervous tissue?\" \n",
    "question_embedding_response = embedding_model.get_embeddings([user_question])\n",
    "question_vector = np.array(question_embedding_response[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "41fbdcd8-a0c1-476c-9faf-8e4690c81a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Cosine similarity: 0.6144\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "similarity = cosine_similarity(question_vector, doc_embedding_vector)\n",
    "print(f\"📊 Cosine similarity: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55a0daa1-67f8-4157-b88c-7794e510b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 Gemini Answer:\n",
      "Based on the text, here's a simple explanation:\n",
      "\n",
      "Nervous tissue is a special type of tissue in your body that's mainly made up of cells called **nerve cells** (or neurons).\n",
      "\n",
      "Its main job, as the text mentions, is to **carry messages**. Think of it like the body's super-fast communication system! These nerve cells work together to send electrical signals and information between your brain, spinal cord, and all the different parts of your body. This allows you to feel things, move, think, and react.\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from vertexai.preview.generative_models import GenerationConfig\n",
    "from vertexai import init\n",
    "\n",
    "# Make sure you're initializing the correct project and region\n",
    "init(project=\"agentic-ai-project-466814\", location=\"us-central1\")\n",
    "\n",
    "# Now create the model\n",
    "gemini = GenerativeModel(\"gemini-2.5-flash\")  # Works now because init() handles the context\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You're a helpful tutor. Here's some science material:\n",
    "\n",
    "--- Start of Content ---\n",
    "{document_text[:3000]}\n",
    "--- End of Content ---\n",
    "\n",
    "Question: {user_question}\n",
    "Answer in a simple, student-friendly way.\n",
    "\"\"\"\n",
    "\n",
    "response = gemini.generate_content(prompt)\n",
    "print(\"💬 Gemini Answer:\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ec66369-4ef9-43e2-a8cc-36e2e160db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔖 Document split into 25 chunks.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Set your desired chunk size (e.g., 500 tokens or ~500-1000 characters)\n",
    "chunk_size = 1000\n",
    "document_chunks = []\n",
    "for i in range(0, len(document_text), chunk_size):\n",
    "    document_chunks.append(document_text[i:i+chunk_size])\n",
    "\n",
    "print(f\"🔖 Document split into {len(document_chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "299de4d7-ec80-4cc2-9b9b-b6a9e2d2a506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunked embeddings and metadata saved to GCS.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "\n",
    "chunk_embeddings = []\n",
    "chunk_metadata = []\n",
    "\n",
    "for idx, chunk in enumerate(document_chunks):\n",
    "    resp = embedding_model.get_embeddings([chunk])\n",
    "    chunk_embeddings.append(resp[0].values)\n",
    "    chunk_metadata.append({\n",
    "        \"chunk_id\": idx,\n",
    "        \"start\": idx * chunk_size,\n",
    "        \"end\": idx * chunk_size + len(chunk),\n",
    "        \"text\": chunk\n",
    "    })\n",
    "\n",
    "chunk_embeddings_array = np.array(chunk_embeddings)\n",
    "# Save embedding vectors\n",
    "emb_buffer = BytesIO()\n",
    "np.save(emb_buffer, chunk_embeddings_array)\n",
    "emb_buffer.seek(0)\n",
    "bucket.blob(\"embeddingsoutput/iesc106_vector_chunks.npy\").upload_from_file(emb_buffer, content_type=\"application/octet-stream\")\n",
    "\n",
    "# Save metadata (chunk text, positions)\n",
    "import pandas as pd\n",
    "meta_df = pd.DataFrame(chunk_metadata)\n",
    "csv_buffer = BytesIO()\n",
    "meta_df.to_csv(csv_buffer, index=False)\n",
    "csv_buffer.seek(0)\n",
    "bucket.blob(\"embeddingsoutput/iesc106_chunk_metadata.csv\").upload_from_file(csv_buffer, content_type=\"text/csv\")\n",
    "print(\"✅ Chunked embeddings and metadata saved to GCS.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08c50c44-ca21-4cdf-8fd3-081ab75edf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📢 Quoted Chunk:\n",
      " 6\n",
      "SCIENCE\n",
      "TISSUES\n",
      "then transmitting the stimulus very rapidly\n",
      "from one place to another within the body. The\n",
      "brain, spinal cord and nerves are all composed\n",
      "of the nervous tissue. The cells of this tissue\n",
      "are called nerve cells or neurons. A neuron\n",
      "consists of a cell body with a nucleus and\n",
      "cytoplasm, from which long thin hair-like\n",
      "parts arise (Fig. 6.12). Usually each neuron\n",
      "has a single long part (process) in the form of\n",
      "a fibre, called the axon, and many short,\n",
      "Nucleus\n",
      "Cell body\n",
      "Dendrite\n",
      "Axon\n",
      "Nerve ending\n",
      "Fig. 6.12: Neuron-a unit of nervous tissue\n",
      "branched parts (processes) called dendrites.\n",
      "An individual nerve cell may be up to a metre\n",
      "long. Many nerve fibres bound together by\n",
      "connective tissue make up a nerve.\n",
      "The signal that passes along the nerve fibre\n",
      "is called a nerve impulse. The nerve impulse\n",
      "from the nerve endings in transmitted to the\n",
      "dendrites of the next nerve cell. Nerve\n",
      "impulses allow us to move our muscles when\n",
      "we want to. The functional combination of\n",
      "nerve and muscle\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings and metadata from GCS (reuse your existing GCS code)\n",
    "emb_blob = bucket.blob(\"embeddingsoutput/iesc106_vector_chunks.npy\")\n",
    "emb_buf = BytesIO()\n",
    "emb_blob.download_to_file(emb_buf)\n",
    "emb_buf.seek(0)\n",
    "chunk_embeds = np.load(emb_buf)\n",
    "\n",
    "meta_blob = bucket.blob(\"embeddingsoutput/iesc106_chunk_metadata.csv\")\n",
    "csv_buf = BytesIO()\n",
    "meta_blob.download_to_file(csv_buf)\n",
    "csv_buf.seek(0)\n",
    "meta_df = pd.read_csv(csv_buf)\n",
    "\n",
    "# Embed the user query\n",
    "user_question = \"What is a nervous tissue?\"\n",
    "query_vec = embedding_model.get_embeddings([user_question])[0].values\n",
    "\n",
    "# Compute cosine similarity for each chunk\n",
    "from numpy.linalg import norm\n",
    "def cosine_similarity(a, b): return np.dot(a, b) / (norm(a) * norm(b))\n",
    "similarities = [cosine_similarity(query_vec, vec) for vec in chunk_embeds]\n",
    "best_idx = int(np.argmax(similarities))\n",
    "best_chunk = meta_df.iloc[best_idx]\n",
    "\n",
    "print(\"📢 Quoted Chunk:\\n\", best_chunk['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef774773-993a-4c5a-ab65-05b1beeb63c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 Explanation:\n",
      " Okay, imagine your body has its own super-fast communication system – that's what **nervous tissue** is all about!\n",
      "\n",
      "Here's a breakdown in simple terms:\n",
      "\n",
      "1.  **What is it?**\n",
      "    *   It's a special type of tissue that helps your body send messages incredibly quickly from one place to another.\n",
      "\n",
      "2.  **Where do you find it?**\n",
      "    *   You find this special tissue in your **brain**, your **spinal cord** (which runs down your back), and in all the **nerves** spread throughout your body.\n",
      "\n",
      "3.  **What are its building blocks?**\n",
      "    *   The tiny building blocks of this communication system are special cells called **nerve cells** or **neurons**.\n",
      "\n",
      "4.  **What does a neuron look like?**\n",
      "    *   Think of a neuron like a tiny tree or a strange-looking star:\n",
      "        *   It has a main \"body\" (the **cell body**) where the \"brain\" of the cell (the nucleus) is.\n",
      "        *   It has one very long \"branch\" or \"tail\" called an **axon**. This is like the main cable that carries the message *away* from the cell body.\n",
      "        *   It has many shorter, twig-like \"branches\" called **dendrites**. These are like antennas that *receive* messages from other cells.\n",
      "    *   Some of these neurons can be surprisingly long – up to a meter! Imagine a single cell stretching from your spine all the way to your toe!\n",
      "\n",
      "5.  **How are \"nerves\" formed?**\n",
      "    *   When many of these long \"cables\" (axons) from different neurons are bundled together, like many wires in an electrical cord, they form a **nerve**.\n",
      "\n",
      "6.  **How do messages travel?**\n",
      "    *   The message itself, which zips along these \"cables,\" is called a **nerve impulse**. It's like a tiny electrical signal or a burst of information.\n",
      "    *   When a message (nerve impulse) reaches the end of one neuron's axon, it jumps over to the dendrites of the *next* neuron, keeping the message moving along the line.\n",
      "\n",
      "7.  **Why is this important?**\n",
      "    *   This amazing system is how your brain tells your muscles to move (like when you want to kick a ball!), how you feel pain or touch, how you see, hear, taste, and smell, and how you think and learn. It's essential for everything your body does!\n",
      "[Chunk 22, chars 22000-23000]\n",
      "Quoted Text: 6\n",
      "SCIENCE\n",
      "TISSUES\n",
      "then transmitting the stimulus very rapidly\n",
      "from one place to another within the body. The\n",
      "brain, spinal cord and nerves are all composed\n",
      "of the nervous tissue. The cells of this tissue\n",
      "are called nerve cells or neurons. A neuron\n",
      "consists of a cell body with a nucleus and\n",
      "cytoplasm, from which long thin hair-like\n",
      "parts arise (Fig. 6.12). Usually each neuron\n",
      "has a single long part (process) in the form of\n",
      "a fibre, called the axon, and many short,\n",
      "Nucleus\n",
      "Cell body\n",
      "Dendrite\n",
      "Axon\n",
      "Nerve ending\n",
      "Fig. 6.12: Neuron-a unit of nervous tissue\n",
      "branched parts (processes) called dendrites.\n",
      "An individual nerve cell may be up to a metre\n",
      "long. Many nerve fibres bound together by\n",
      "connective tissue make up a nerve.\n",
      "The signal that passes along the nerve fibre\n",
      "is called a nerve impulse. The nerve impulse\n",
      "from the nerve endings in transmitted to the\n",
      "dendrites of the next nerve cell. Nerve\n",
      "impulses allow us to move our muscles when\n",
      "we want to. The functional combination of\n",
      "nerve and muscle\n",
      "\n",
      "Explanation: Okay, imagine your body has its own super-fast communication system – that's what **nervous tissue** is all about!\n",
      "\n",
      "Here's a breakdown in simple terms:\n",
      "\n",
      "1.  **What is it?**\n",
      "    *   It's a special type of tissue that helps your body send messages incredibly quickly from one place to another.\n",
      "\n",
      "2.  **Where do you find it?**\n",
      "    *   You find this special tissue in your **brain**, your **spinal cord** (which runs down your back), and in all the **nerves** spread throughout your body.\n",
      "\n",
      "3.  **What are its building blocks?**\n",
      "    *   The tiny building blocks of this communication system are special cells called **nerve cells** or **neurons**.\n",
      "\n",
      "4.  **What does a neuron look like?**\n",
      "    *   Think of a neuron like a tiny tree or a strange-looking star:\n",
      "        *   It has a main \"body\" (the **cell body**) where the \"brain\" of the cell (the nucleus) is.\n",
      "        *   It has one very long \"branch\" or \"tail\" called an **axon**. This is like the main cable that carries the message *away* from the cell body.\n",
      "        *   It has many shorter, twig-like \"branches\" called **dendrites**. These are like antennas that *receive* messages from other cells.\n",
      "    *   Some of these neurons can be surprisingly long – up to a meter! Imagine a single cell stretching from your spine all the way to your toe!\n",
      "\n",
      "5.  **How are \"nerves\" formed?**\n",
      "    *   When many of these long \"cables\" (axons) from different neurons are bundled together, like many wires in an electrical cord, they form a **nerve**.\n",
      "\n",
      "6.  **How do messages travel?**\n",
      "    *   The message itself, which zips along these \"cables,\" is called a **nerve impulse**. It's like a tiny electrical signal or a burst of information.\n",
      "    *   When a message (nerve impulse) reaches the end of one neuron's axon, it jumps over to the dendrites of the *next* neuron, keeping the message moving along the line.\n",
      "\n",
      "7.  **Why is this important?**\n",
      "    *   This amazing system is how your brain tells your muscles to move (like when you want to kick a ball!), how you feel pain or touch, how you see, hear, taste, and smell, and how you think and learn. It's essential for everything your body does!\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''\n",
    "Here's a quote from the source document:\n",
    "\n",
    "\"{best_chunk['text']}\"\n",
    "\n",
    "Explain the above in simple terms for a student.\n",
    "'''\n",
    "\n",
    "response = gemini.generate_content(prompt)\n",
    "print(\"💬 Explanation:\\n\", response.text)\n",
    "print(f\"[Chunk {best_idx}, chars {best_chunk['start']}-{best_chunk['end']}]\")\n",
    "print(\"Quoted Text:\", best_chunk['text'])\n",
    "print(\"\\nExplanation:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "450801e0-2c04-4c7d-9940-7de1357ffdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata for 35 chunks.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "from vertexai import init\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = \"agentic-ai-project-466814\"\n",
    "LOCATION = \"us-central1\"\n",
    "BUCKET_NAME = \"studyplanandcontent\"\n",
    "DOC_JSON_PATH = \"output/17996961397770261561/0/iesc106-0.json\"\n",
    "GCS_SAVE_PATH_PREFIX = \"embeddingsoutput/iesc106_vector_chunk\"\n",
    "GCS_META_PATH = \"embeddingsoutput/iesc106_chunk_metadata.csv\"\n",
    "\n",
    "# Initialize Vertex AI\n",
    "init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Fetch Document AI output JSON from GCS\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(DOC_JSON_PATH)\n",
    "docai_json = json.loads(blob.download_as_text())\n",
    "\n",
    "# Chunk full document text\n",
    "document_text = docai_json.get(\"text\", \"\")\n",
    "chunk_size = 700\n",
    "chunks = [document_text[i:i+chunk_size] for i in range(0, len(document_text), chunk_size)]\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "\n",
    "# Metadata for saving (to help link embeddings to text later)\n",
    "meta = []\n",
    "\n",
    "# Generate embeddings, upload each chunk\n",
    "for idx, chunk_text in enumerate(chunks):\n",
    "    if not chunk_text.strip():\n",
    "        continue\n",
    "    embedding_response = embedding_model.get_embeddings([chunk_text])\n",
    "    embedding_vector = embedding_response[0].values\n",
    "\n",
    "    # Save embedding to bytes buffer and upload\n",
    "    buffer = BytesIO()\n",
    "    np.save(buffer, np.array(embedding_vector))\n",
    "    buffer.seek(0)\n",
    "    chunk_save_path = f\"{GCS_SAVE_PATH_PREFIX}_{idx}.npy\"\n",
    "    embedding_blob = bucket.blob(chunk_save_path)\n",
    "    embedding_blob.upload_from_file(buffer, content_type=\"application/octet-stream\")\n",
    "\n",
    "    # Collect metadata info (add whatever extra fields needed)\n",
    "    meta.append({\n",
    "        \"chunk_idx\": idx,\n",
    "        \"start\": idx * chunk_size,\n",
    "        \"end\": min((idx+1)*chunk_size, len(document_text)),\n",
    "        \"text\": chunk_text,\n",
    "        \"embedding_path\": chunk_save_path\n",
    "    })\n",
    "\n",
    "# Save metadata CSV to GCS\n",
    "meta_df = pd.DataFrame(meta)\n",
    "csv_buf = BytesIO()\n",
    "meta_df.to_csv(csv_buf, index=False)\n",
    "csv_buf.seek(0)\n",
    "meta_blob = bucket.blob(GCS_META_PATH)\n",
    "meta_blob.upload_from_file(csv_buf, content_type=\"text/csv\")\n",
    "print(f\"Saved metadata for {len(meta_df)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbc2aa1a-af70-4433-ba9b-56a16de5ec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagad\\anaconda3\\envs\\testingopenai\\Lib\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full chunk text:\n",
      "ecide.\n",
      "Such muscles are called voluntary muscles\n",
      "Features\n",
      "Shape\n",
      "Number of nuclei\n",
      "Position of nuclei\n",
      "Striated\n",
      "Smooth Cardiac\n",
      "6.3.4 NERVOUS TISSUE\n",
      "All cells possess the ability to respond to\n",
      "stimuli. However, cells of the nervous tissue\n",
      "are highly specialised for being stimulated and\n",
      "68\n",
      "Reprint 2025-26\n",
      "SCIENCE\n",
      "TISSUES\n",
      "then transmitting the stimulus very rapidly\n",
      "from one place to another within the body. The\n",
      "brain, spinal cord and nerves are all composed\n",
      "of the nervous tissue. The cells of this tissue\n",
      "are called nerve cells or neurons. A neuron\n",
      "consists of a cell body with a nucleus and\n",
      "cytoplasm, from which long thin hair-like\n",
      "parts arise (Fig. 6.12). Usually each neuron\n",
      "has a single long part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagad\\anaconda3\\envs\\testingopenai\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation generated by Gemini:\n",
      "Of course! Here is an explanation of that text in simple terms for a student.\n",
      "\n",
      "***\n",
      "\n",
      "### Your Body's Super-Fast Messaging System: Nervous Tissue\n",
      "\n",
      "Imagine your body is a giant team, and your brain is the coach. How does the coach instantly tell the players (your hands, feet, etc.) what to do? It uses a super-fast messaging system called the **nervous tissue**.\n",
      "\n",
      "Here’s what the text explains:\n",
      "\n",
      "**1. A Very Special Job**\n",
      "*   Almost all cells in your body can react to things around them (like heat or touch).\n",
      "*   But the cells in your nervous tissue are **specialists**. Their main job is to receive a message (a \"stimulus\") and pass it along *incredibly fast* from one part of your body to another.\n",
      "\n",
      "**2. Where Do You Find It?**\n",
      "*   This special tissue makes up your body's main communication network:\n",
      "    *   **The Brain:** The main control center.\n",
      "    *   **The Spinal Cord:** The major highway for messages going up and down your body.\n",
      "    *   **The Nerves:** The smaller roads that connect the highway to every single part of your body.\n",
      "\n",
      "**3. The Building Blocks: Neurons**\n",
      "*   The special cells that make up this tissue are called **nerve cells** or **neurons**. Think of them as the individual messengers running along the network.\n",
      "\n",
      "**4. What a Neuron Looks Like**\n",
      "*   A neuron has a main part called the **cell body**, which contains its \"brain\" (the nucleus).\n",
      "*   Sticking out from the cell body are long, thin, **hair-like parts**. These are like the arms and legs of the neuron, used to send and receive messages.\n",
      "*   Usually, each neuron has **one extra-long part** that acts like a main cable to send a message a long distance.\n",
      "\n",
      "**In short: Nervous tissue is what your brain, spinal cord, and nerves are made of. It's built from special cells called neurons that act like lightning-fast messengers, allowing your brain to talk to the rest of your body in an instant.**\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "\n",
    "PROJECT_ID = \"agentic-ai-project-466814\"\n",
    "BUCKET_NAME = \"studyplanandcontent\"\n",
    "GCS_SAVE_PATH_PREFIX = \"embeddingsoutput/iesc106_vector_chunk\"\n",
    "GCS_META_PATH = \"embeddingsoutput/iesc106_chunk_metadata.csv\"\n",
    "\n",
    "# Set up GCS\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "# Load metadata (to know chunk count and file names)\n",
    "meta_blob = bucket.blob(GCS_META_PATH)\n",
    "csv_buf = BytesIO()\n",
    "meta_blob.download_to_file(csv_buf)\n",
    "csv_buf.seek(0)\n",
    "meta_df = pd.read_csv(csv_buf)\n",
    "\n",
    "# Load all embeddings based on metadata file paths\n",
    "embeddings = []\n",
    "for idx, row in meta_df.iterrows():\n",
    "    emb_blob = bucket.blob(row['embedding_path'])\n",
    "    emb_buf = BytesIO()\n",
    "    emb_blob.download_to_file(emb_buf)\n",
    "    emb_buf.seek(0)\n",
    "    vector = np.load(emb_buf)\n",
    "    embeddings.append(vector)\n",
    "embeddings = np.array(embeddings)  # Shape: (num_chunks, embedding_dim)\n",
    "\n",
    "# Get user question embedding\n",
    "user_question = \"What is a nervous tissue?\"\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "query_vec = embedding_model.get_embeddings([user_question])[0].values\n",
    "\n",
    "# Cosine similarity\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "similarities = [cosine_similarity(query_vec, emb) for emb in embeddings]\n",
    "best_idx = int(np.argmax(similarities))\n",
    "best_chunk = meta_df.iloc[best_idx]\n",
    "\n",
    "# Assuming meta_df and best_idx are already defined and loaded\n",
    "best_chunk = meta_df.iloc[best_idx]  # best_idx=31 in your case\n",
    "\n",
    "# Show the full text of the best chunk\n",
    "print(\"Full chunk text:\")\n",
    "print(best_chunk['text'])\n",
    "\n",
    "# Prepare the prompt and call Gemini\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "gemini = GenerativeModel(\"gemini-2.5-pro\")\n",
    "prompt = f'''\n",
    "Here's a quote from the source document:\n",
    "\n",
    "\"{best_chunk['text']}\"\n",
    "\n",
    "Explain the above in simple terms for a student.\n",
    "'''\n",
    "response = gemini.generate_content(prompt)\n",
    "print(\"Explanation generated by Gemini:\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b43b8d8c-9e2d-44c7-a250-bc69bf35059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 1\n",
      "\n",
      "--- Chunk 0 ---\n",
      "with some line breaks but no consistent double newline paragraph markers...\n"
     ]
    }
   ],
   "source": [
    "def auto_chunk_text_by_lines(text, max_chunk_size=700, min_line_length=30):\n",
    "    \"\"\"\n",
    "    Auto-detect paragraphs by grouping lines.\n",
    "\n",
    "    Splits text by newlines, filters out very short lines (likely headers or noise),\n",
    "    then groups lines until chunk size limit is reached.\n",
    "    \"\"\"\n",
    "\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        # Skip very short lines that may be separators or noise\n",
    "        if len(line) < min_line_length:\n",
    "            continue\n",
    "\n",
    "        if len(current_chunk) + len(line) + 1 > max_chunk_size:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = line\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                current_chunk += \"\\n\" + line\n",
    "            else:\n",
    "                current_chunk = line\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example Usage\n",
    "document_text = \"\"\"Your long text input here, \n",
    "with some line breaks but no consistent double newline paragraph markers\"\"\"\n",
    "\n",
    "chunks = auto_chunk_text_by_lines(document_text)\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {idx} ---\\n{chunk[:300]}...\")  # print chunk preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e605851-b5ad-4ef7-b1b0-c00af7f0d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] Initializing Vertex AI...\n",
      "[Init] Vertex AI Initialized\n",
      "[GCS] Initializing Google Cloud Storage client...\n",
      "[GCS] Bucket 'studyplanandcontent' connected\n",
      "[Fetch] Downloading document JSON from gs://studyplanandcontent/output/17996961397770261561/0/iesc106-0.json ...\n",
      "[Fetch] Document JSON downloaded and parsed\n",
      "[Text] Total document length: 24018 characters\n",
      "[Chunk] Creating chunks of the document automatically...\n",
      "[Chunk] Created 31 chunks\n",
      "[Embed] Loading embedding model 'text-embedding-005'...\n",
      "[Embed] Embedding model ready\n",
      "[Embed] Generating embedding for chunk 0 (length=688)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 0 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_0.npy\n",
      "[Embed] Generating embedding for chunk 1 (length=658)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 1 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_1.npy\n",
      "[Embed] Generating embedding for chunk 2 (length=656)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 2 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_2.npy\n",
      "[Embed] Generating embedding for chunk 3 (length=683)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 3 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_3.npy\n",
      "[Embed] Generating embedding for chunk 4 (length=696)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 4 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_4.npy\n",
      "[Embed] Generating embedding for chunk 5 (length=692)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 5 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_5.npy\n",
      "[Embed] Generating embedding for chunk 6 (length=667)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 6 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_6.npy\n",
      "[Embed] Generating embedding for chunk 7 (length=667)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 7 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_7.npy\n",
      "[Embed] Generating embedding for chunk 8 (length=674)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 8 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_8.npy\n",
      "[Embed] Generating embedding for chunk 9 (length=687)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 9 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_9.npy\n",
      "[Embed] Generating embedding for chunk 10 (length=684)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 10 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_10.npy\n",
      "[Embed] Generating embedding for chunk 11 (length=658)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 11 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_11.npy\n",
      "[Embed] Generating embedding for chunk 12 (length=679)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 12 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_12.npy\n",
      "[Embed] Generating embedding for chunk 13 (length=664)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 13 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_13.npy\n",
      "[Embed] Generating embedding for chunk 14 (length=698)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 14 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_14.npy\n",
      "[Embed] Generating embedding for chunk 15 (length=700)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 15 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_15.npy\n",
      "[Embed] Generating embedding for chunk 16 (length=695)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 16 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_16.npy\n",
      "[Embed] Generating embedding for chunk 17 (length=672)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 17 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_17.npy\n",
      "[Embed] Generating embedding for chunk 18 (length=665)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 18 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_18.npy\n",
      "[Embed] Generating embedding for chunk 19 (length=698)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 19 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_19.npy\n",
      "[Embed] Generating embedding for chunk 20 (length=685)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 20 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_20.npy\n",
      "[Embed] Generating embedding for chunk 21 (length=671)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 21 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_21.npy\n",
      "[Embed] Generating embedding for chunk 22 (length=697)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 22 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_22.npy\n",
      "[Embed] Generating embedding for chunk 23 (length=687)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 23 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_23.npy\n",
      "[Embed] Generating embedding for chunk 24 (length=656)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 24 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_24.npy\n",
      "[Embed] Generating embedding for chunk 25 (length=696)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 25 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_25.npy\n",
      "[Embed] Generating embedding for chunk 26 (length=699)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 26 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_26.npy\n",
      "[Embed] Generating embedding for chunk 27 (length=664)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 27 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_27.npy\n",
      "[Embed] Generating embedding for chunk 28 (length=675)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 28 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_28.npy\n",
      "[Embed] Generating embedding for chunk 29 (length=650)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 29 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_29.npy\n",
      "[Embed] Generating embedding for chunk 30 (length=581)...\n",
      "[Embed] Embedding vector size: 768\n",
      "[Upload] Uploaded chunk 30 embedding to gs://studyplanandcontent/embeddingsoutput/iesc106_vector_chunk_30.npy\n",
      "[Meta] Prepared metadata for 31 chunks\n",
      "[Meta] Uploaded metadata CSV to gs://studyplanandcontent/embeddingsoutput/iesc106_chunk_metadata.csv\n",
      "[Done] Step 1 complete: All chunks embedded and saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "from vertexai import init\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = \"agentic-ai-project-466814\"\n",
    "LOCATION = \"us-central1\"\n",
    "BUCKET_NAME = \"studyplanandcontent\"\n",
    "DOC_JSON_PATH = \"output/17996961397770261561/0/iesc106-0.json\"\n",
    "GCS_EMBEDDING_PATH_PREFIX = \"embeddingsoutput/iesc106_vector_chunk\"\n",
    "GCS_META_PATH = \"embeddingsoutput/iesc106_chunk_metadata.csv\"\n",
    "\n",
    "print(\"[Init] Initializing Vertex AI...\")\n",
    "init(project=PROJECT_ID, location=LOCATION)\n",
    "print(\"[Init] Vertex AI Initialized\")\n",
    "\n",
    "print(\"[GCS] Initializing Google Cloud Storage client...\")\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "print(f\"[GCS] Bucket '{BUCKET_NAME}' connected\")\n",
    "\n",
    "# Download document JSON\n",
    "print(f\"[Fetch] Downloading document JSON from gs://{BUCKET_NAME}/{DOC_JSON_PATH} ...\")\n",
    "blob = bucket.blob(DOC_JSON_PATH)\n",
    "docai_json = json.loads(blob.download_as_text())\n",
    "print(\"[Fetch] Document JSON downloaded and parsed\")\n",
    "\n",
    "document_text = docai_json.get(\"text\", \"\")\n",
    "print(f\"[Text] Total document length: {len(document_text)} characters\")\n",
    "\n",
    "def auto_chunk_text_by_lines(text, max_chunk_size=700, min_line_length=30):\n",
    "    \"\"\"\n",
    "    Auto-detect paragraphs by grouping lines.\n",
    "    Splits text by newlines, filters out short/noise lines, groups until near max_chunk_size.\n",
    "    \"\"\"\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        # Skip very short lines (likely headers/noise)\n",
    "        if len(line) < min_line_length:\n",
    "            continue\n",
    "\n",
    "        if len(current_chunk) + len(line) + 1 > max_chunk_size:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = line\n",
    "        else:\n",
    "            current_chunk = current_chunk + \"\\n\" + line if current_chunk else line\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "print(\"[Chunk] Creating chunks of the document automatically...\")\n",
    "chunks = auto_chunk_text_by_lines(document_text, max_chunk_size=700)\n",
    "print(f\"[Chunk] Created {len(chunks)} chunks\")\n",
    "\n",
    "print(\"[Embed] Loading embedding model 'text-embedding-005'...\")\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "print(\"[Embed] Embedding model ready\")\n",
    "\n",
    "meta = []\n",
    "\n",
    "for idx, chunk_text in enumerate(chunks):\n",
    "    print(f\"[Embed] Generating embedding for chunk {idx} (length={len(chunk_text)})...\")\n",
    "    embedding_response = embedding_model.get_embeddings([chunk_text])\n",
    "    embedding_vector = embedding_response[0].values\n",
    "    print(f\"[Embed] Embedding vector size: {len(embedding_vector)}\")\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    np.save(buffer, np.array(embedding_vector))\n",
    "    buffer.seek(0)\n",
    "\n",
    "    chunk_save_path = f\"{GCS_EMBEDDING_PATH_PREFIX}_{idx}.npy\"\n",
    "    embedding_blob = bucket.blob(chunk_save_path)\n",
    "    embedding_blob.upload_from_file(buffer, content_type=\"application/octet-stream\")\n",
    "    print(f\"[Upload] Uploaded chunk {idx} embedding to gs://{BUCKET_NAME}/{chunk_save_path}\")\n",
    "\n",
    "    meta.append({\n",
    "        \"chunk_idx\": idx,\n",
    "        \"start\": None,  # Optional: you can calculate character indices if needed\n",
    "        \"end\": None,\n",
    "        \"text\": chunk_text,\n",
    "        \"embedding_path\": chunk_save_path\n",
    "    })\n",
    "\n",
    "print(f\"[Meta] Prepared metadata for {len(meta)} chunks\")\n",
    "\n",
    "meta_df = pd.DataFrame(meta)\n",
    "csv_buf = BytesIO()\n",
    "meta_df.to_csv(csv_buf, index=False)\n",
    "csv_buf.seek(0)\n",
    "\n",
    "meta_blob = bucket.blob(GCS_META_PATH)\n",
    "meta_blob.upload_from_file(csv_buf, content_type=\"text/csv\")\n",
    "print(f\"[Meta] Uploaded metadata CSV to gs://{BUCKET_NAME}/{GCS_META_PATH}\")\n",
    "\n",
    "print(\"[Done] Step 1 complete: All chunks embedded and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c16eea6e-9e89-4097-a1bf-261be36c815d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] Initializing Google Cloud Storage client...\n",
      "[Init] Connected to bucket 'studyplanandcontent'\n",
      "[Load] Downloading metadata CSV from gs://studyplanandcontent/embeddingsoutput/iesc106_chunk_metadata.csv ...\n",
      "[Load] Loaded metadata for 31 chunks\n",
      "[Load] Downloading all chunk embeddings...\n",
      "  [Load] Chunk 0 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 1 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 2 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 3 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 4 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 5 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 6 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 7 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 8 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 9 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 10 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 11 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 12 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 13 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 14 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 15 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 16 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 17 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 18 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 19 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 20 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 21 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 22 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 23 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 24 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 25 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 26 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 27 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 28 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 29 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 30 embedding loaded, shape=(768,)\n",
      "[Load] All embeddings loaded with shape (31, 768)\n",
      "[Query] Embedding user question: 'What is a nervous tissue?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagad\\anaconda3\\envs\\testingopenai\\Lib\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query] Query embedding vector size: 768\n",
      "[Compare] Computing cosine similarities...\n",
      "  [Compare] Chunk 0: similarity=0.5737\n",
      "  [Compare] Chunk 1: similarity=0.5842\n",
      "  [Compare] Chunk 2: similarity=0.4889\n",
      "  [Compare] Chunk 3: similarity=0.5129\n",
      "  [Compare] Chunk 4: similarity=0.5345\n",
      "  [Compare] Chunk 5: similarity=0.4514\n",
      "  [Compare] Chunk 6: similarity=0.4563\n",
      "  [Compare] Chunk 7: similarity=0.5687\n",
      "  [Compare] Chunk 8: similarity=0.5463\n",
      "  [Compare] Chunk 9: similarity=0.5511\n",
      "  [Compare] Chunk 10: similarity=0.5008\n",
      "  [Compare] Chunk 11: similarity=0.4684\n",
      "  [Compare] Chunk 12: similarity=0.4830\n",
      "  [Compare] Chunk 13: similarity=0.4997\n",
      "  [Compare] Chunk 14: similarity=0.5133\n",
      "  [Compare] Chunk 15: similarity=0.5782\n",
      "  [Compare] Chunk 16: similarity=0.5957\n",
      "  [Compare] Chunk 17: similarity=0.6118\n",
      "  [Compare] Chunk 18: similarity=0.5548\n",
      "  [Compare] Chunk 19: similarity=0.5359\n",
      "  [Compare] Chunk 20: similarity=0.5087\n",
      "  [Compare] Chunk 21: similarity=0.5448\n",
      "  [Compare] Chunk 22: similarity=0.5361\n",
      "  [Compare] Chunk 23: similarity=0.5700\n",
      "  [Compare] Chunk 24: similarity=0.5600\n",
      "  [Compare] Chunk 25: similarity=0.5726\n",
      "  [Compare] Chunk 26: similarity=0.5772\n",
      "  [Compare] Chunk 27: similarity=0.5709\n",
      "  [Compare] Chunk 28: similarity=0.7184\n",
      "  [Compare] Chunk 29: similarity=0.6990\n",
      "  [Compare] Chunk 30: similarity=0.6381\n",
      "\n",
      "[Result] Best chunk index: 28 with similarity: 0.7184\n",
      "[Result] Chunk text preview:\n",
      "All cells possess the ability to respond to\n",
      "stimuli. However, cells of the nervous tissue\n",
      "are highly specialised for being stimulated and\n",
      "then transmitting the stimulus very rapidly\n",
      "from one place to another within the body. The\n",
      "brain, spinal cord and nerves are all composed\n",
      "of the nervous tissue. The cells of this tissue\n",
      "are called nerve cells or neurons. A neuron\n",
      "consists of a cell body with a nucleus and\n",
      "cytoplasm, from which long thin hair-like\n",
      "parts arise (Fig. 6.12). Usually each neuron\n",
      "ha...\n",
      "\n",
      "[Gemini] Initializing Gemini model...\n",
      "[Gemini] Sending prompt to Gemini...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagad\\anaconda3\\envs\\testingopenai\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gemini] Response received (length: 1551)\n",
      "\n",
      "=== Explanation ===\n",
      "Of course! Here is that explanation broken down in simple terms for a student.\n",
      "\n",
      "***\n",
      "\n",
      "Imagine your body has its own super-fast internet or messaging system. This is your **nervous system**.\n",
      "\n",
      "Here’s what the text explains about it:\n",
      "\n",
      "*   **Special Messenger Cells:** While all cells in your body can react to things happening around them (a \"stimulus,\" like heat or touch), the cells of your nervous system are experts. Their main job is to act like messengers that carry signals very, very quickly across your body.\n",
      "\n",
      "*   **Where You Find Them:** These special cells make up your body's \"command center\" and \"wiring\": the **brain**, the **spinal cord**, and all the **nerves**.\n",
      "\n",
      "*   **The Name of the Cell:** Each one of these special messenger cells is called a **neuron**.\n",
      "\n",
      "### The Parts of a Neuron\n",
      "\n",
      "Think of a neuron like a tree with one very long root.\n",
      "\n",
      "1.  **The Cell Body:** This is the main part of the cell, like the base of the tree. It contains the neuron's control center (the nucleus) and its internal jelly (the cytoplasm).\n",
      "\n",
      "2.  **Dendrites:** These are many **short, bushy branches** that grow out of the cell body. They act like antennas, picking up signals from other cells.\n",
      "\n",
      "3.  **The Axon:** This is **one single, long fiber** that extends from the cell body. It acts like a long cable, carrying the message away from the cell to pass it on to the next one.\n",
      "\n",
      "**In short: A neuron is a special cell in your nervous system built to receive a message (with its dendrites) and then zap it down its long axon to another part of your body.**\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from numpy.linalg import norm\n",
    "\n",
    "PROJECT_ID = \"agentic-ai-project-466814\"\n",
    "BUCKET_NAME = \"studyplanandcontent\"\n",
    "GCS_META_PATH = \"embeddingsoutput/iesc106_chunk_metadata.csv\"\n",
    "\n",
    "print(\"[Init] Initializing Google Cloud Storage client...\")\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "print(f\"[Init] Connected to bucket '{BUCKET_NAME}'\")\n",
    "\n",
    "print(f\"[Load] Downloading metadata CSV from gs://{BUCKET_NAME}/{GCS_META_PATH} ...\")\n",
    "meta_blob = bucket.blob(GCS_META_PATH)\n",
    "csv_buf = BytesIO()\n",
    "meta_blob.download_to_file(csv_buf)\n",
    "csv_buf.seek(0)\n",
    "\n",
    "meta_df = pd.read_csv(csv_buf)\n",
    "num_chunks = len(meta_df)\n",
    "print(f\"[Load] Loaded metadata for {num_chunks} chunks\")\n",
    "\n",
    "print(\"[Load] Downloading all chunk embeddings...\")\n",
    "embeddings = []\n",
    "for idx, row in meta_df.iterrows():\n",
    "    emb_blob = bucket.blob(row['embedding_path'])\n",
    "    emb_buf = BytesIO()\n",
    "    emb_blob.download_to_file(emb_buf)\n",
    "    emb_buf.seek(0)\n",
    "    vector = np.load(emb_buf)\n",
    "    embeddings.append(vector)\n",
    "    print(f\"  [Load] Chunk {idx} embedding loaded, shape={vector.shape}\")\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "print(f\"[Load] All embeddings loaded with shape {embeddings.shape}\")\n",
    "\n",
    "user_question = \"What is a nervous tissue?\"\n",
    "print(f\"[Query] Embedding user question: '{user_question}'\")\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "query_vec = embedding_model.get_embeddings([user_question])[0].values\n",
    "print(f\"[Query] Query embedding vector size: {len(query_vec)}\")\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "print(\"[Compare] Computing cosine similarities...\")\n",
    "similarities = []\n",
    "for idx, chunk_vec in enumerate(embeddings):\n",
    "    sim = cosine_similarity(query_vec, chunk_vec)\n",
    "    similarities.append(sim)\n",
    "    print(f\"  [Compare] Chunk {idx}: similarity={sim:.4f}\")\n",
    "\n",
    "best_idx = int(np.argmax(similarities))\n",
    "best_similarity = similarities[best_idx]\n",
    "best_chunk = meta_df.iloc[best_idx]\n",
    "\n",
    "print(f\"\\n[Result] Best chunk index: {best_idx} with similarity: {best_similarity:.4f}\")\n",
    "print(f\"[Result] Chunk text preview:\\n{best_chunk['text'][:500]}...\\n\")\n",
    "\n",
    "print(\"[Gemini] Initializing Gemini model...\")\n",
    "gemini = GenerativeModel(\"gemini-2.5-pro\")\n",
    "prompt = f'''\n",
    "Here's a quote from the source document:\n",
    "\n",
    "\"{best_chunk[\"text\"]}\"\n",
    "\n",
    "Explain the above in simple terms for a student.\n",
    "'''\n",
    "print(\"[Gemini] Sending prompt to Gemini...\")\n",
    "response = gemini.generate_content(prompt)\n",
    "print(f\"[Gemini] Response received (length: {len(response.text)})\")\n",
    "\n",
    "print(\"\\n=== Explanation ===\")\n",
    "print(response.text)\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b03e0554-231f-4107-9ece-03b78e762550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] Initializing Google Cloud Storage client...\n",
      "[Init] Connected to bucket 'studyplanandcontent'\n",
      "[Load] Downloading metadata CSV from gs://studyplanandcontent/embeddingsoutput/iesc106_chunk_metadata.csv ...\n",
      "[Load] Loaded metadata for 31 chunks\n",
      "[Load] Downloading all chunk embeddings...\n",
      "  [Load] Chunk 0 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 1 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 2 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 3 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 4 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 5 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 6 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 7 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 8 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 9 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 10 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 11 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 12 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 13 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 14 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 15 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 16 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 17 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 18 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 19 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 20 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 21 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 22 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 23 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 24 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 25 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 26 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 27 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 28 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 29 embedding loaded, shape=(768,)\n",
      "  [Load] Chunk 30 embedding loaded, shape=(768,)\n",
      "[Load] All embeddings loaded with shape (31, 768)\n",
      "[Query] Embedding user question: 'What is nervous tissue?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagad\\anaconda3\\envs\\testingopenai\\Lib\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query] Query embedding vector size: 768\n",
      "[Compare] Computing cosine similarities for each chunk...\n",
      "  [Compare] Chunk 0: similarity=0.5609\n",
      "  [Compare] Chunk 1: similarity=0.5693\n",
      "  [Compare] Chunk 2: similarity=0.4962\n",
      "  [Compare] Chunk 3: similarity=0.5130\n",
      "  [Compare] Chunk 4: similarity=0.5360\n",
      "  [Compare] Chunk 5: similarity=0.4600\n",
      "  [Compare] Chunk 6: similarity=0.4740\n",
      "  [Compare] Chunk 7: similarity=0.5611\n",
      "  [Compare] Chunk 8: similarity=0.5485\n",
      "  [Compare] Chunk 9: similarity=0.5467\n",
      "  [Compare] Chunk 10: similarity=0.5018\n",
      "  [Compare] Chunk 11: similarity=0.4634\n",
      "  [Compare] Chunk 12: similarity=0.4756\n",
      "  [Compare] Chunk 13: similarity=0.5027\n",
      "  [Compare] Chunk 14: similarity=0.5177\n",
      "  [Compare] Chunk 15: similarity=0.5711\n",
      "  [Compare] Chunk 16: similarity=0.5933\n",
      "  [Compare] Chunk 17: similarity=0.6047\n",
      "  [Compare] Chunk 18: similarity=0.5420\n",
      "  [Compare] Chunk 19: similarity=0.5226\n",
      "  [Compare] Chunk 20: similarity=0.4970\n",
      "  [Compare] Chunk 21: similarity=0.5296\n",
      "  [Compare] Chunk 22: similarity=0.5373\n",
      "  [Compare] Chunk 23: similarity=0.5663\n",
      "  [Compare] Chunk 24: similarity=0.5447\n",
      "  [Compare] Chunk 25: similarity=0.5778\n",
      "  [Compare] Chunk 26: similarity=0.5661\n",
      "  [Compare] Chunk 27: similarity=0.5574\n",
      "  [Compare] Chunk 28: similarity=0.7124\n",
      "  [Compare] Chunk 29: similarity=0.6904\n",
      "  [Compare] Chunk 30: similarity=0.6314\n",
      "\n",
      "[Result] Best chunk index: 28 with similarity: 0.7124\n",
      "[Result] Chunk text preview (full sentences):\n",
      "All cells possess the ability to respond to\n",
      "stimuli. However, cells of the nervous tissue\n",
      "are highly specialised for being stimulated and\n",
      "then transmitting the stimulus very rapidly\n",
      "from one place to another within the body. The\n",
      "brain, spinal cord and nerves are all composed\n",
      "of the nervous tissue. The cells of this tissue\n",
      "are called nerve cells or neurons. A neuron\n",
      "consists of a cell body with a nucleus and\n",
      "cytoplasm, from which long thin hair-like\n",
      "parts arise (Fig. 6.12).\n",
      "\n",
      "[Gemini] Initializing Gemini generative model...\n",
      "[Gemini] Sending prompt to Gemini model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagad\\anaconda3\\envs\\testingopenai\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gemini] Response received (length: 1961)\n",
      "\n",
      "=== Explanation ===\n",
      "Of course! Here is that explanation broken down into simple terms for a student.\n",
      "\n",
      "***\n",
      "\n",
      "Imagine your body is a big, busy city. For anything to happen, different parts of the city need to talk to each other, and they need to do it fast!\n",
      "\n",
      "### Your Body's Super-Fast Messengers\n",
      "\n",
      "The quote explains that your body has a special, high-speed communication system.\n",
      "\n",
      "*   **All cells can react:** Think of every cell in your body as a person. Every person can react to things, like moving away if something is too hot.\n",
      "*   **Nerve cells are specialists:** But some cells, called **nerve cells** (or **neurons**), are like professional messengers. Their only job is to receive a message (a \"stimulus\") and pass it along to another part of the body at incredible speed.\n",
      "\n",
      "### Where Are These Messengers Found?\n",
      "\n",
      "These special nerve cells make up your body's main control network:\n",
      "\n",
      "*   **The Brain:** The main control center.\n",
      "*   **The Spinal Cord:** The major highway for messages running up and down your back.\n",
      "*   **Nerves:** The smaller roads and cables that branch out to every single part of your body.\n",
      "\n",
      "### What a Single Messenger (Neuron) Looks Like\n",
      "\n",
      "If you zoom in on one of these nerve cells, it looks a bit like a tree with a very long trunk. It has three main parts:\n",
      "\n",
      "1.  **Cell Body:** This is the main part of the cell, like the headquarters. It contains the cell's \"brain\" (the nucleus).\n",
      "2.  **Dendrites:** These are many short, bushy branches that stick out from the cell body. Think of them as **antennas**. Their job is to **receive messages** from other nerve cells.\n",
      "3.  **Axon:** This is one **single, long arm** that extends away from the cell body. Think of it as a **transmitter cable**. Its job is to **send the message** on to the next cell.\n",
      "\n",
      "**In short:** A message arrives at the \"antennas\" (dendrites), gets processed in the \"headquarters\" (cell body), and is then sent out at high speed along the \"long cable\" (axon) to the next cell in the chain.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from numpy.linalg import norm\n",
    "\n",
    "PROJECT_ID = \"agentic-ai-project-466814\"\n",
    "BUCKET_NAME = \"studyplanandcontent\"\n",
    "GCS_META_PATH = \"embeddingsoutput/iesc106_chunk_metadata.csv\"\n",
    "\n",
    "def preview_full_sentences_simple(text, max_chars=500):\n",
    "    \"\"\"\n",
    "    Returns text truncated at the last period before max_chars to avoid incomplete sentences.\n",
    "    If no period found, returns raw truncated snippet.\n",
    "    \"\"\"\n",
    "    if len(text) <= max_chars:\n",
    "        return text\n",
    "    snippet = text[:max_chars]\n",
    "    last_period = snippet.rfind('.')\n",
    "    if last_period == -1:\n",
    "        return snippet.strip()\n",
    "    return snippet[:last_period + 1].strip()\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "print(\"[Init] Initializing Google Cloud Storage client...\")\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "print(f\"[Init] Connected to bucket '{BUCKET_NAME}'\")\n",
    "\n",
    "print(f\"[Load] Downloading metadata CSV from gs://{BUCKET_NAME}/{GCS_META_PATH} ...\")\n",
    "meta_blob = bucket.blob(GCS_META_PATH)\n",
    "csv_buf = BytesIO()\n",
    "meta_blob.download_to_file(csv_buf)\n",
    "csv_buf.seek(0)\n",
    "meta_df = pd.read_csv(csv_buf)\n",
    "num_chunks = len(meta_df)\n",
    "print(f\"[Load] Loaded metadata for {num_chunks} chunks\")\n",
    "\n",
    "print(\"[Load] Downloading all chunk embeddings...\")\n",
    "embeddings = []\n",
    "for idx, row in meta_df.iterrows():\n",
    "    emb_blob = bucket.blob(row['embedding_path'])\n",
    "    emb_buf = BytesIO()\n",
    "    emb_blob.download_to_file(emb_buf)\n",
    "    emb_buf.seek(0)\n",
    "    vector = np.load(emb_buf)\n",
    "    embeddings.append(vector)\n",
    "    print(f\"  [Load] Chunk {idx} embedding loaded, shape={vector.shape}\")\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "print(f\"[Load] All embeddings loaded with shape {embeddings.shape}\")\n",
    "\n",
    "# User query to search\n",
    "user_question = \"What is nervous tissue?\"\n",
    "print(f\"[Query] Embedding user question: '{user_question}'\")\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
    "query_vec = embedding_model.get_embeddings([user_question])[0].values\n",
    "print(f\"[Query] Query embedding vector size: {len(query_vec)}\")\n",
    "\n",
    "print(\"[Compare] Computing cosine similarities for each chunk...\")\n",
    "similarities = []\n",
    "for idx, chunk_vec in enumerate(embeddings):\n",
    "    sim = cosine_similarity(query_vec, chunk_vec)\n",
    "    similarities.append(sim)\n",
    "    print(f\"  [Compare] Chunk {idx}: similarity={sim:.4f}\")\n",
    "\n",
    "best_idx = int(np.argmax(similarities))\n",
    "best_similarity = similarities[best_idx]\n",
    "best_chunk = meta_df.iloc[best_idx]\n",
    "\n",
    "print(f\"\\n[Result] Best chunk index: {best_idx} with similarity: {best_similarity:.4f}\")\n",
    "\n",
    "# Generate preview of chunk text ending at a full sentence\n",
    "preview_text = preview_full_sentences_simple(best_chunk['text'], max_chars=500)\n",
    "print(f\"[Result] Chunk text preview (full sentences):\\n{preview_text}\\n\")\n",
    "\n",
    "# Generate explanation with Gemini\n",
    "print(\"[Gemini] Initializing Gemini generative model...\")\n",
    "gemini = GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "prompt = f'''\n",
    "Here's a quote from the source document:\n",
    "\n",
    "\"{best_chunk[\"text\"]}\"\n",
    "\n",
    "Explain the above in simple terms for a student.\n",
    "'''\n",
    "\n",
    "print(\"[Gemini] Sending prompt to Gemini model...\")\n",
    "response = gemini.generate_content(prompt)\n",
    "print(f\"[Gemini] Response received (length: {len(response.text)})\")\n",
    "\n",
    "print(\"\\n=== Explanation ===\")\n",
    "print(response.text)\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba1afd5b-1615-4fb8-9c4a-b1aeb10da593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gemini] Requesting automated study plan from Gemini...\n",
      "[Gemini] Study plan generated.\n",
      "\n",
      "Of course! Here is a detailed, 14-day self-study plan for the chapter \"Tissues.\" Let's get you prepared and confident. You've got this!\n",
      "\n",
      "### **Your 14-Day Mission: Master the World of Tissues**\n",
      "\n",
      "This plan is designed for one hour of focused study each day. Remember to find a quiet spot, keep your phone away, and have your notes and practice materials ready. Let's begin!\n",
      "\n",
      "---\n",
      "\n",
      "#### **PART 1: PLANT TISSUES (Days 1-4)**\n",
      "\n",
      "**Day 1: The Basics & Growing Tissues (Meristematic)**\n",
      "*   **Topic:** Introduction to Tissues & Meristematic Tissue.\n",
      "*   **What to Cover:**\n",
      "    *   Understand what a tissue is and why complex organisms like plants and animals need them for organized work.\n",
      "    *   Focus on what makes meristematic tissues special: they are actively dividing cells responsible for growth.\n",
      "    *   Learn the three types based on their location: Apical (at the tips for length), Lateral (on the sides for width), and Intercalary (at the base of leaves/internodes).\n",
      "*   **Practice:** Draw a simple plant shoot and root, and mark the locations of the three types of meristematic tissue. Answer 5-7 very short questions on their function.\n",
      "*   **Special Tip:** Think of meristematic tissue as the \"construction crew\" of the plant, always building new parts.\n",
      "\n",
      "**Day 2: The Specialists (Simple Permanent Tissues)**\n",
      "*   **Topic:** Simple Permanent Tissues.\n",
      "*   **What to Cover:**\n",
      "    *   Learn how these tissues are formed from meristematic cells through a process called differentiation, where cells take on a specific role and stop dividing.\n",
      "    *   Study the three types: Parenchyma (the basic \"packing\" and food storage tissue), Collenchyma (provides flexibility to parts like stems), and Sclerenchyma (provides hardness and strength, made of dead cells).\n",
      "*   **Practice:** Create a simple table comparing these three tissues based on cell type (living/dead), cell wall thickness, and main function.\n",
      "*   **Special Tip:** Connect the structure to the function. For example, sclerenchyma has very thick, hard walls because its job is to make the plant tough (like in the husk of a coconut).\n",
      "\n",
      "**Day 3: The Transport System (Complex Permanent Tissues)**\n",
      "*   **Topic:** Complex Permanent Tissues.\n",
      "*   **What to Cover:**\n",
      "    *   Understand why they are called \"complex\": they are made of more than one type of cell working together.\n",
      "    *   Focus on Xylem: its job is to transport water and minerals from roots to the rest of the plant (a one-way street).\n",
      "    *   Focus on Phloem: its job is to transport food from leaves to all other parts (a two-way street).\n",
      "    *   Briefly learn about the different cells that make up xylem and phloem.\n",
      "*   **Practice:** Draw two simple diagrams with arrows showing the direction of movement in xylem and phloem in a plant.\n",
      "*   **Special Tip:** Use an analogy! Xylem is like the water pipes in a house, and phloem is like a food delivery service that can go anywhere.\n",
      "\n",
      "**Day 4: Plant Tissues Revision Day**\n",
      "*   **Topic:** Review of all Plant Tissues.\n",
      "*   **What to Cover:**\n",
      "    *   Quickly go over your notes from the last three days.\n",
      "    *   Create a flowchart or a mind map that shows how all plant tissues are related (e.g., Tissues -> Meristematic & Permanent -> Simple & Complex, etc.).\n",
      "    *   Review the key differences between all the tissues you've learned so far.\n",
      "*   **Practice:** Solve at least 15 mixed practice questions covering all plant tissue topics. Focus on \"identify the tissue\" type questions.\n",
      "*   **Special Tip:** When you review, try to explain each concept out loud to yourself. This helps lock it into your memory.\n",
      "\n",
      "---\n",
      "\n",
      "#### **PART 2: ANIMAL TISSUES (Days 5-9)**\n",
      "\n",
      "**Day 5: The Covering & Lining Tissues (Epithelial)**\n",
      "*   **Topic:** Epithelial Tissue.\n",
      "*   **What to Cover:**\n",
      "    *   Understand that this tissue's main job is to cover body surfaces and line internal organs, acting as a barrier.\n",
      "    *   Learn the types based on cell shape (squamous - flat, cuboidal - cube-shaped, columnar - pillar-like).\n",
      "    *   Understand the difference between simple (one layer) and stratified (many layers) epithelium.\n",
      "*   **Practice:** Match the types of epithelial tissue with their locations (e.g., Squamous -> lining of the mouth, Columnar -> intestine).\n",
      "*   **Special Tip:** The name often gives you a clue! \"Squamous\" sounds like \"scales,\" and they are flat like scales. \"Stratified\" means layered, like a layered cake.\n",
      "\n",
      "**Day 6: The Connecting & Supporting Tissues (Connective - Part 1)**\n",
      "*   **Topic:** Connective Tissues (Blood, Bone, Cartilage).\n",
      "*   **What to Cover:**\n",
      "    *   Learn the defining feature: cells are loosely spaced and embedded in a substance called the matrix.\n",
      "    *   Focus on Blood: its matrix is a fluid called plasma. Its job is transport.\n",
      "    *   Focus on Bone: its matrix is hard and provides the body's framework.\n",
      "    *   Focus on Cartilage: it has a solid but flexible matrix, found in places like the ear and nose tip.\n",
      "*   **Practice:** Write down two key differences between bone and cartilage.\n",
      "*   **Special Tip:** Pay close attention to the \"matrix\" for each type. The nature of the matrix defines the function of the tissue.\n",
      "\n",
      "**Day 7: The Binding Tissues (Connective - Part 2)**\n",
      "*   **Topic:** Connective Tissues (Ligaments, Tendons, Areolar, Adipose).\n",
      "*   **What to Cover:**\n",
      "    *   Learn the difference between Ligaments (connect bone to bone) and Tendons (connect muscle to bone).\n",
      "    *   Understand Areolar tissue as the \"filler\" or \"packing\" tissue found between organs.\n",
      "    *   Learn about Adipose tissue, which stores fat and acts as an insulator.\n",
      "*   **Practice:** Answer questions that ask you to differentiate between a ligament and a tendon.\n",
      "*   **Special Tip:** Use a simple mnemonic to remember: **LBB** (Ligament connects Bone to Bone) and **TMB** (Tendon connects Muscle to Bone).\n",
      "\n",
      "**Day 8: The Movement & Messaging Tissues (Muscular & Nervous)**\n",
      "*   **Topic:** Muscular and Nervous Tissues.\n",
      "*   **What to Cover:**\n",
      "    *   Muscular Tissue: responsible for movement. Learn the three types: Striated (voluntary, in our limbs), Smooth (involuntary, in internal organs), and Cardiac (involuntary, only in the heart).\n",
      "    *   Nervous Tissue: responsible for sending messages throughout the body.\n",
      "    *   Focus on the basic structure of a nerve cell (neuron): cell body, dendrites, and axon.\n",
      "*   **Practice:** Draw and label a neat diagram of a neuron. Create a table comparing the three types of muscle tissue.\n",
      "*   **Special Tip:** For muscle types, focus on two things: what they look like (striped or not) and whether you can control them consciously.\n",
      "\n",
      "**Day 9: Animal Tissues Revision Day**\n",
      "*   **Topic:** Review of all Animal Tissues.\n",
      "*   **What to Cover:**\n",
      "    *   Look through your notes on the four major types: Epithelial, Connective, Muscular, and Nervous.\n",
      "    *   Create a large mind map showing all the animal tissues and their sub-types.\n",
      "    *   Briefly list the main function and one location for each tissue type you've studied.\n",
      "*   **Practice:** Solve at least 15-20 mixed questions on all animal tissues.\n",
      "*   **Special Tip:** Focus on function. If a question describes a function (e.g., \"which tissue helps you lift your bag?\"), you should be able to identify the tissue (Striated Muscle).\n",
      "\n",
      "---\n",
      "\n",
      "#### **PART 3: CONSOLIDATION & TESTING (Days 10-14)**\n",
      "\n",
      "**Day 10: Comparing Plants & Animals**\n",
      "*   **Topic:** Differentiating Plant and Animal Tissues.\n",
      "*   **What to Cover:**\n",
      "    *   Think about the major differences in their lifestyles (plants are stationary, animals move).\n",
      "    *   How does this lifestyle affect their tissues? (e.g., plants need more supportive, dead tissue; animals need more living tissue for energy and movement).\n",
      "    *   Compare their growth patterns and tissue organization.\n",
      "*   **Practice:** Create a T-chart listing at least 4-5 key differences between plant and animal tissues.\n",
      "*   **Special Tip:** This is a \"big picture\" day. Understanding *why* they are different is more important than just listing the differences.\n",
      "\n",
      "**Day 11: Diagram Power-Up**\n",
      "*   **Topic:** Diagram Practice.\n",
      "*   **What to Cover:**\n",
      "    *   This entire session is for drawing and labeling.\n",
      "    *   Practice the most important diagrams: Neuron, the three muscle types, sections of xylem and phloem, and different epithelial tissues.\n",
      "*   **Practice:** Draw each key diagram from memory. Compare it with the correct version in your notes, and then draw it again.\n",
      "*   **Special Tip:** Neatness and correct labeling are crucial. Use a sharp pencil and a ruler for label lines. This skill fetches easy marks in exams!\n",
      "\n",
      "**Day 12: Question Blitz**\n",
      "*   **Topic:** Solving Higher-Order Questions.\n",
      "*   **What to Cover:**\n",
      "    *   Go beyond simple recall questions.\n",
      "    *   Focus on \"Give Reason\" and \"What would happen if...\" type questions.\n",
      "    *   Practice identifying tissues from pictures or functional descriptions.\n",
      "*   **Practice:** Solve a dedicated worksheet of challenging questions. Time yourself to improve your speed.\n",
      "*   **Special Tip:** For \"Give Reason\" questions, always link structure to function in your answer.\n",
      "\n",
      "**Day 13: The Mock Test**\n",
      "*   **Topic:** Self-Testing.\n",
      "*   **What to Cover:**\n",
      "    *   Create a test for yourself (or use a sample paper) covering the entire chapter.\n",
      "    *   Spend 45 minutes taking the test under exam conditions (no notes, no distractions).\n",
      "    *   Spend the last 15 minutes checking your answers and understanding your mistakes.\n",
      "*   **Practice:** The test itself is the practice. The key is the analysis you do after.\n",
      "*   **Special Tip:** Be honest with yourself! The goal is to find your weak spots so you can fix them before the real test.\n",
      "\n",
      "**Day 14: Final Polish & Review**\n",
      "*   **Topic:** Final Consolidation.\n",
      "*   **What to Cover:**\n",
      "    *   Quickly review all your mind maps, tables, and flowcharts.\n",
      "    *   Pay special attention to the topics you found difficult during your mock test.\n",
      "    *   Read through your notes one last time to refresh your memory.\n",
      "*   **Practice:** Verbally summarize the entire chapter to a family member or just to yourself.\n",
      "*   **Special Tip:** You've done the hard work. Be confident and stay calm. You are well-prepared!\n",
      "\n",
      "Great work on committing to this plan. Stick to it, and you'll master this chapter completely\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "\n",
    "# Initialize Gemini model\n",
    "gemini = GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "def create_study_plan(subject_name, total_days=14, session_minutes=60):\n",
    "    prompt = f\"\"\"\n",
    "Act as an expert school tutor who is planning a self-study schedule for a middle school student.\n",
    "Do NOT quote or refer to the book text. \n",
    "Assume the subject is \"{subject_name}\". Assume the kid has access to good notes, book material, and practice questions.\n",
    "Create a detailed, step-by-step study plan for {total_days} days, with each study session lasting {session_minutes} minutes (1 hour per day).\n",
    "Split the subject into logical topics and assign each to different days as appropriate.\n",
    "For each day, provide:\n",
    "- Topic(s) to be studied\n",
    "- 3-5 bullet points, in your own words, summarizing what the student should cover or focus on\n",
    "- The type of practice or revision the student should do\n",
    "- Anything to pay special attention to or tips\n",
    "\n",
    "Be concise, clear, and motivating.\n",
    "\"\"\"\n",
    "\n",
    "    print(\"[Gemini] Requesting automated study plan from Gemini...\")\n",
    "    response = gemini.generate_content(prompt)\n",
    "    print(\"[Gemini] Study plan generated.\\n\")\n",
    "    print(response.text)\n",
    "\n",
    "# Example usage (update subject_name as needed)\n",
    "create_study_plan(subject_name=\"Tissues in Science (Grade 9 NCERT)\", total_days=14, session_minutes=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25416945-e6e1-4d61-8caa-dd701a361b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
